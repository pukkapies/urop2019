This folder contains the script needed to properly clean the Million Songs Dataset. We implicitly assume you _do_ have access to the dataset (how to get it? really good question...). We also assume you downloaded the Last.fm database from [here](http://millionsongdataset.com/lastfm/), or that you manually obtained it using the Last.fm API. 

## Data Cleaning

Each script can be run in terminal by typing `python <script name.py>`. Each script also has an `--help` page containing all the information you might need about options and parameters. Here is an outline of the correct workflow:

 - Use `python fetcher.py <options> output.csv` to create a `.csv` file containing a list of file paths, the 7Digital ID of the tracks, and some extra information from the Million Songs Dataset tracks saved locally (the filenames are supposed to be of the form 7Digital ID + '.clip.mp3');

- Use `python wrangler.py <options> input.csv output.csv` to read the `.csv` file generated by `fetcher.py` and create a `.csv` file linking each track to its track ID (the HDF5 summary file can be download [here](http://millionsongdataset.com/sites/default/files/AdditionalFiles/msd_summary_file.h5)), and also to remove unwanted entries such as mismatches, duplicates or files which can't be opened;

- Use `python mp3_to_numpy.py <options> input.csv` to read the `.csv` file generated by `wrangler.py` (or by `fetcher.py`, if you also want mismatched tracks) and create the `.npz` files which will allow us to spot silent tracks and analyse silent sections within non-silent tracks;

- use `python wrangler_silence.py <options> input.csv output.csv` to read the `.csv` file generated by `wrangler.py` (or, again, by `fetcher.py`) and look for the `.npz` files generated by `mp3_to_numpt.py` in order to create a file containing _only_ the tracks which satisfy certain requirements, such as a minimal effective length or a maximal amount of silence (that is, the final tracks that you want to use in your model);

- use `python lastfm_cleaning.py` to read the final `.csv` file generated by `wrangler_silence.py` and produce a final tags database (similar in structure to the original one, in order to allow compatibility with our querying module) containing only clean and meaningful tags (`lastfm_cleaning_tools.py` does the heavy lifting here, if you are planning to check out the code...).

You will now have a `.csv` file containing only the tracks that you are happy to use, and a new `.db` file containing clean tags information for the tracks.

## Data Cleaning, Advanced Tags Filtering

Here is a brief tutorial of how you might customise our tags filtering algorithm:

**Step 1:** Produce the popularity dataframe. This dataframe contains ranking of tags based on the number of occurrences in the tags database. 

```python
from lastfm import LastFm

popularity = LastFm('path/to/lastfm_tags.db').popularity()
```

**Step 2:** Generate the five `.txt` files (`non_genre_list.txt`, `male_list.txt`, `female_list.txt`, `vocal_list.txt`, `instrumental_list.txt`) that will be used to manually select the tags.

```python
set_txt_path('/output/dir') # set output path for .txt files

generate_genre_txt(popularity, threshold=2000)
generate_vocal_txt(popularity, tag_list = ['rap', 'instrumental', 'male', 'female'], percentage_list=[90, 90, 90, 80])
```

**Step 3:** Open the `.txt` files and put a symbol ‘-’ in front of the tags that you would like to discard, and append a suffix ‘_filtered‘ to the  the amended `.txt` filenames (e.g. `male_list.txt` should be renamed to `male_list_filtered.txt`).

**Step 4:** Run `generate_genre_df()` and `generate_vocal_df()`.

```python
generate_genre_df(popularity, threshold=2000, sub_threshold = 10, indicator='-') # sub_threshold tells the search algorithm to search only on tags with occurrence ≥ 10
generate_vocal_df(indicator='-')
```

**Step 5:** Run `generate_final_df()` (after taking a look at the output of `generate_genre_df()` and `generate_vocal_df()` to see if you are happy) with your favourite specifications for the `combine_list` and `drop_list` parameters (fine-tuning) to produce the final output.

```python
df_final = generate_final_df(from_csv_path='/srv/data/urop', threshold=2000, sub_threshold=10, combine_list=[[‘rhythm and blues’, ‘rnb’], [‘funky’, ‘funk’]], drop_list=[‘2000’, ‘00’, ‘90’, ‘80’, ‘70’, ‘60’])
```

**Step 6:** Use `lastfm_cleaning.py` to turn the tags info dataframe in a `.db` file.

All the searching methods mentioned will be run automatically on the genre tags when you call `generate_final_df()` or `generate_genre_df()`. You might also run extra define your own custom search function `fn()`, which takes any tag as input
and returns a transformed tag (based on the function) as an output (an example of such function in the script is `clean_1()`). You might then do the following

```python
# define a dataframe which acts as the tag pool, in this example, the entire popularity dataset is used
popularity = popularity.copy()

# run the search with the new search function fn(), where tags with occurrence ≥ 10 from the popularity dataset will be in the tag pool
df = generate_genre_df()
df = search_genre(popularity, df, search_method=fn, search_tags_list=None, sub_threshold=10)
```

If `search_tags_list` is `None`, all the tags from the `df` dataframe will act as target tags, and the algorithm will search for matching tags for each target tag. If `search_tags_list` is a list of tags, only tags in the list will act as the target tags. The set of target tags must be a subset of the set of tags in `df`.

If you are feeling brave, you may run your costom searches one-by-one using`search_genre()` and then re-combine your own genre dataset with the vocal dataset to produce the final one.

See the documentation within `lastfm_cleaning_utils.py` for more details.
